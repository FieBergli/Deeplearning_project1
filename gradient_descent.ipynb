{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the same results with train and train_manual_update\n",
    "- Write torch.manual_seed(42) at the beginning of your notebook.\n",
    "- Write torch.set_default_dtype(torch.double) at the beginning of your notebook to alleviate precision errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_default_dtype(torch.double)\n",
    "rng = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "Load, analyse and preprocess the CIFAR-10 dataset. Split it into 3\n",
    "datasets: training, validation and test. Take a subset of these datasets\n",
    "by keeping only 2 labels: cat and car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_classes(dataset, keep_classes):\n",
    "    # Filter out samples that do not belong to the classes we want to keep\n",
    "    # Give them 0, 1 class labels\n",
    "    new_samples = [(data, keep_classes.index(label)) for data, label in dataset if label in keep_classes]\n",
    "    return new_samples\n",
    "\n",
    "def load_cifar(train_val_split=0.9, data_path=\"data\", preprocessor=None):\n",
    "        \n",
    "    if preprocessor is None:\n",
    "        preprocessor = transforms.Compose([\n",
    "            transforms.Resize((16, 16)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    # Load CIFAR10 dataset training and validation sets\n",
    "    cifar10_train_val = datasets.CIFAR10(\n",
    "    data_path,      \n",
    "    train=True,     \n",
    "    download=True,\n",
    "    transform=preprocessor\n",
    "    )\n",
    "    # Load CIFAR10 dataset test set\n",
    "    cifar10_test = datasets.CIFAR10(\n",
    "        data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=preprocessor\n",
    "    )\n",
    "\n",
    "    # Keep only classes 1 (automobile) and 3 (cat)\n",
    "    keep_classes = [1, 3]\n",
    "    cifar10_train_val = filter_classes(cifar10_train_val, keep_classes)\n",
    "    cifar10_test = filter_classes(cifar10_test, keep_classes)\n",
    "\n",
    "    # Split the training set into training and validation sets\n",
    "    n_train_val = len(cifar10_train_val)\n",
    "    n_train = int(n_train_val * (train_val_split))\n",
    "    n_val = n_train_val - n_train \n",
    "    \n",
    "    cifar10_train, cifar10_val = random_split(cifar10_train_val, lengths=[n_train, n_val], generator=rng)\n",
    "\n",
    "    print(f\"Number of training samples: {len(cifar10_train)}\")\n",
    "    print(f\"Number of validation samples: {len(cifar10_val)}\")\n",
    "    print(f\"Number of test samples: {len(cifar10_test)}\")\n",
    "   \n",
    "    return cifar10_train, cifar10_val, cifar10_test\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            # Forward pass by passing the images through the model\n",
    "            outputs = model.forward(images)\n",
    "            preds = torch.argmax(outputs, dim=1) #index of the maximum value in each of the 64 images\n",
    "            bool_tensor = torch.eq(preds, labels)\n",
    "            correct += torch.sum(bool_tensor).item()\n",
    "            total += preds.shape[0]\n",
    "            \n",
    "    accuracy = correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_val, cifar_test = load_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the class balance in the training set\n",
    "class_balance = [0, 0]\n",
    "for _, label in cifar_train:\n",
    "    class_balance[label] += 1\n",
    "print(f\"Class balance in the training set: {class_balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some images from the cifar_train dataset and their corresponding labels\n",
    "# show a specified number (int pictures) of images of each class\n",
    "def show_images(dataset, pictures):\n",
    "    fig, axs = plt.subplots(2, pictures, figsize=(15, 5))\n",
    "    auto_count = 0\n",
    "    cat_count = 0\n",
    "    i = 0\n",
    "    while auto_count < pictures or cat_count < pictures:\n",
    "        img, label = dataset[i]\n",
    "        if label == 0 and auto_count < pictures:\n",
    "            axs[0, auto_count].imshow(np.clip(img.permute(1, 2, 0).numpy(), 0, 1))\n",
    "            axs[0, auto_count].set_title(\"automobile\")\n",
    "            axs[0, auto_count].axis(\"off\")\n",
    "            auto_count += 1\n",
    "        elif label == 1 and cat_count < pictures:\n",
    "            axs[1, cat_count].imshow(np.clip(img.permute(1, 2, 0).numpy(), 0, 1))\n",
    "            axs[1, cat_count].set_title(\"cat\")\n",
    "            axs[1, cat_count].axis(\"off\")\n",
    "            cat_count += 1\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(cifar_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and standard deviation of the training set with the two classes\n",
    "def compute_mean_std(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)  # Number of images in batch\n",
    "        images = images.view(batch_samples, images.shape[1], -1)  # Flatten each image\n",
    "        mean += images.mean(dim=[0, 2]) * batch_samples\n",
    "        std += images.std(dim=[0, 2]) * batch_samples\n",
    "        total_samples += batch_samples\n",
    "\n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(cifar_train)\n",
    "\n",
    "print(f\"Computed mean: {mean}\")\n",
    "print(f\"Computed std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalization transform using computed mean and std\n",
    "normalize_transform = transforms.Normalize(mean.tolist(), std.tolist())\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    return [(normalize_transform(image), label) for image, label in dataset]\n",
    "\n",
    "cifar_train = normalize_dataset(cifar_train)\n",
    "cifar_val = normalize_dataset(cifar_val)\n",
    "cifar_test = normalize_dataset(cifar_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show images from the cifar_train dataset after normalization\n",
    "show_images(cifar_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a MyMLP class that implements a MLP in PyTorch (so only fully\n",
    "connected layers) such that:\n",
    "    \n",
    "    - The input dimension is 768(= 16 ∗ 16 ∗ 3) and the output dimension is 2 (for the 2 classes).\n",
    "    - The hidden layers have respectively 128 and 32 hidden units.\n",
    "    - All activation functions are ReLU. The last layer has no activation function since the cross-entropy loss already includes a softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = nn.Sequential(\n",
    "            torch.nn.Linear(16*16*3, 128), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(128, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train(n_epochs, optimizer, model, loss_fn, train_loader) function that trains model for n_epochs epochs given an optimizer optimizer, a loss function loss_fn and a dataloader train_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, model, loss_fn, train_loader, n_epochs = 10):\n",
    "    train_losses = []\n",
    "    print(\"--------- Using Pytorch's SGD ---------\")\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device=('cpu'), dtype=torch.double)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if (epoch) == 1 or (epoch) % 5 == 0:\n",
    "            now = datetime.now()\n",
    "            print(f\"{now}  (manual train) | Epoch {epoch} / {n_epochs} | Training Loss: {train_loss:.5f}\")\n",
    "\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a similar function train manual_update that has no optimizer parameter, but a learning rate lr parameter instead and that manually updates each trainable parameter of model using equation (2). Do not forget to zero out all gradients after each iteration. \n",
    "\n",
    "Train 2 instances of MyMLP, one using train and the other using train_manual_update (use the same parameter values for both models). Compare their respective training losses. To get exactly the same results with both functions, see section 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(model, loss_fn, train_loader, lr=1e-2, momentum_coeff=0., weight_decay=0., n_epochs = 30):\n",
    "    train_losses = []\n",
    "    print(\"--------- Using manual update ----------\")\n",
    "    \n",
    "    velocity = {p: torch.zeros_like(p) for p in model.parameters()}\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device='cpu', dtype=torch.double)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    grad_with_decay = p.grad + weight_decay * p.data\n",
    "                    velocity[p] = momentum_coeff * velocity[p] - lr * grad_with_decay\n",
    "                    p.data += velocity[p]\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            model.zero_grad()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if (epoch) == 1 or (epoch) % 5 == 0:\n",
    "            now = datetime.now()\n",
    "            print(f\"{now}  (manual train) | Epoch {epoch} / {n_epochs} | Training Loss: {train_loss:.5f}\")\n",
    "        \n",
    "    return train_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(cifar_train, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(cifar_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(cifar_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, model_manuel, train_loader, val_loader, n_epochs=30, loss_fn=loss_fn, lr=0.01, weight_decay=0, momentum_coeff=0.):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum_coeff)\n",
    "    accuracies = {}\n",
    "    \n",
    "    train_losses = train(optimizer, model, loss_fn, train_loader, n_epochs)\n",
    "    train_accuracy = compute_accuracy(model, train_loader)\n",
    "    val_accuracy = compute_accuracy(model, val_loader)\n",
    "\n",
    "    print()\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "    print()\n",
    "\n",
    "    train_losses_manuel = train_manual_update(model_manuel, loss_fn, train_loader, lr=lr, weight_decay=weight_decay, n_epochs=n_epochs, momentum_coeff=momentum_coeff)\n",
    "    train_accuracy_manuel = compute_accuracy(model_manuel, train_loader)\n",
    "    val_accuracy_manuel = compute_accuracy(model_manuel, val_loader)\n",
    "    print()\n",
    "    print(\"--- Accuracies ---\")\n",
    "    print(f\"Train accuracy (manual): {train_accuracy_manuel:.4f}\")\n",
    "    print(f\"Validation accuracy (manual): {val_accuracy_manuel:.4f}\")\n",
    "\n",
    "    accuracies['train'] = train_accuracy\n",
    "    accuracies['val'] = val_accuracy\n",
    "    accuracies['train_manuel'] = train_accuracy_manuel\n",
    "    accuracies['val_manuel'] = val_accuracy_manuel\n",
    "\n",
    "    return train_losses, train_losses_manuel, accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model1_1 = MyMLP()\n",
    "torch.manual_seed(SEED)\n",
    "model1_2 = MyMLP()\n",
    "\n",
    "train_losses_1, train_losses_manuel_1, accuracies1 = train_and_validate(model1_1, model1_2, train_loader, val_loader)\n",
    "results.append((train_losses_1, train_losses_manuel_1))\n",
    "\n",
    "accuracies[model1_1] = accuracies1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model2_1 = MyMLP()\n",
    "torch.manual_seed(SEED)\n",
    "model2_2 = MyMLP()\n",
    "\n",
    "train_losses_2, train_losses_manuel_2, accuracies2= train_and_validate(model2_1, model2_2, train_loader, val_loader, weight_decay=0.01,  lr=0.01)\n",
    "results.append((train_losses_2, train_losses_manuel_2))\n",
    "accuracies[model2_1] = accuracies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model3_1 = MyMLP()\n",
    "torch.manual_seed(SEED)\n",
    "model3_2 = MyMLP()\n",
    "\n",
    "train_losses_3, train_losses_manuel_3, accuracies3 = train_and_validate(model3_1, model3_2, train_loader, val_loader, momentum_coeff=0.85,  lr=0.01)\n",
    "results.append((train_losses_3, train_losses_manuel_3))\n",
    "accuracies[model3_1] = accuracies3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model4_1 = MyMLP()\n",
    "torch.manual_seed(SEED)\n",
    "model4_2 = MyMLP()\n",
    "\n",
    "train_losses_4, train_losses_manuel_4, accuracies4 = train_and_validate(model4_1, model4_2, train_loader, val_loader, momentum_coeff=0.85, weight_decay=0.001,  lr=0.01)\n",
    "results.append((train_losses_4, train_losses_manuel_4))\n",
    "accuracies[model4_1] = accuracies4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model5_1 = MyMLP()\n",
    "torch.manual_seed(SEED)\n",
    "model5_2 = MyMLP()\n",
    "\n",
    "train_losses_5, train_losses_manuel_5, accuracies5 = train_and_validate(model5_1, model5_2, train_loader, val_loader, momentum_coeff=0.85, weight_decay=0.001,  lr=0.05)\n",
    "results.append((train_losses_5, train_losses_manuel_5))\n",
    "accuracies[model5_1] = accuracies5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all train losses over the iterations for the models in the same plot\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(results)))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    train_losses, _ = results[i]\n",
    "    ax.plot(train_losses, label=f\"SGD - {i+1}\", linewidth=3, color=colors[i])\n",
    "\n",
    "ax.set_title(\"Training Losses for Different Runs\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all train losses over the iterations for the models separat plots\n",
    "fig, axs = plt.subplots(5, 2, figsize=(15, 20))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    train_losses, train_losses_manuel = results[i]\n",
    "    axs[i, 0].plot(train_losses, label=\"SGD\")\n",
    "    axs[i, 0].set_title(f\"SGD - {i+1}\")\n",
    "    axs[i, 0].set_xlabel(\"Epoch\")\n",
    "    axs[i, 0].set_ylabel(\"Loss\")\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    axs[i, 1].plot(train_losses_manuel, label=\"Manual\")\n",
    "    axs[i, 1].set_title(f\"Manual - {i+1}\")\n",
    "    axs[i, 1].set_xlabel(\"Epoch\")\n",
    "    axs[i, 1].set_ylabel(\"Loss\")\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the last train_loss from each model in a single plot bar\n",
    "train_losses = [train_losses_1[-1], train_losses_2[-1], train_losses_3[-1], train_losses_4[-1], train_losses_5[-1]]\n",
    "train_losses_manuel = [train_losses_manuel_1[-1], train_losses_manuel_2[-1], train_losses_manuel_3[-1], train_losses_manuel_4[-1], train_losses_manuel_5[-1]]\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(train_losses))\n",
    "bars1 = ax.bar(index, train_losses, bar_width, label=\"SGD\")\n",
    "bars2 = ax.bar(index + bar_width, train_losses_manuel, bar_width, label=\"Manual\")\n",
    "\n",
    "# Add values above the bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Final train loss\")\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels([f\"{i+1}\" for i in range(len(train_losses))])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(accuracies.keys())\n",
    "\n",
    "model_names_string = []\n",
    "for i in range(len(model_names)):\n",
    "    model_names_string.append(f\"Model {i+1}\")\n",
    "\n",
    "# Extract the accuracies\n",
    "train_acc = [accuracies[model]['train'] for model in model_names]\n",
    "val_acc = [accuracies[model]['val'] for model in model_names]\n",
    "train_acc_manual = [accuracies[model]['train_manuel'] for model in model_names]\n",
    "val_acc_manual = [accuracies[model]['val_manuel'] for model in model_names]\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    print(f\"Model {i+1} - Train Accuracy: {train_acc[i]:.4f}\")\n",
    "    print(f\"Model {i+1} - Validation Accuracy: {val_acc[i]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.15\n",
    "x = range(len(model_names))\n",
    "\n",
    "# Plotting the bars\n",
    "plt.bar(x, train_acc, bar_width, label=\"Train Accuracy (PyTorch Optimizer)\", color='skyblue')\n",
    "plt.bar([p + bar_width for p in x], val_acc, bar_width, label=\"Validation Accuracy (PyTorch Optimizer)\", color='orange')\n",
    "# If you want to include manual update accuracies, you can uncomment these lines\n",
    "plt.bar([p + bar_width * 2 for p in x], train_acc_manual, bar_width, label=\"Train Accuracy (Manual Update)\", color='green')\n",
    "plt.bar([p + bar_width * 3 for p in x], val_acc_manual, bar_width, label=\"Validation Accuracy (Manual Update)\", color='purple')\n",
    "\n",
    "# Set labels, title, and legend\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Comparison of Model Accuracies\")\n",
    "plt.xticks([p + bar_width / 2 for p in x], model_names_string)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = max(accuracies, key=lambda x: accuracies[x]['val'])\n",
    "# get the index of the best model\n",
    "best_model_name = model_names_string[model_names.index(best_model)]\n",
    "print(f\"Best model: {best_model_name} \")\n",
    "\n",
    "# save the accuracies train and validation of the best model\n",
    "best_model_train_acc = accuracies[best_model]['train']\n",
    "best_model_val_acc = accuracies[best_model]['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the best model\n",
    "test_accuracy = compute_accuracy(best_model, test_loader)\n",
    "print(f\"Test accuracy of the best model: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training, validation, and test accuracies of the best model and plot them\n",
    "accuracies = [best_model_train_acc, best_model_val_acc, test_accuracy]\n",
    "labels = ['Train', 'Validation', 'Test']\n",
    "\n",
    "plt.bar(labels, accuracies)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "for i, accuracy in enumerate(accuracies):\n",
    "    plt.text(i, accuracy + 0.02, f'{accuracy:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Best Model Accuracies ({best_model_name})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = best_model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Automobile', 'Cat'], yticklabels=['Automobile', 'Cat'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
